{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c554fe5c",
   "metadata": {},
   "source": [
    "\n",
    "# Most Popular Re-ranking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b966e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_PATH: C:\\Users\\LEEYS\\Desktop\\yamyam-lab\\src\n",
      "CONFIG_PATH: C:\\Users\\LEEYS\\Desktop\\yamyam-lab\\config/models/mf/als.yaml\n",
      "PREPROCESS_CONFIG_PATH: C:\\Users\\LEEYS\\Desktop\\yamyam-lab\\config/preprocess/preprocess.yaml\n",
      "RESULT_ROOT: C:\\Users\\LEEYS\\Desktop\\yamyam-lab\\result/untest/most_popular/20250825211407\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"1\"  \n",
    "\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys, traceback\n",
    "from datetime import datetime\n",
    "\n",
    "from typing import Optional, Dict, List, Tuple, Iterable\n",
    "\n",
    "dt = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "test = \"untest\"\n",
    "model = \"most_popular\"\n",
    "config_model = \"als\"  \n",
    "\n",
    "\n",
    "PARENTS_PATH = Path(os.getcwd()).resolve().parent\n",
    "CONFIG_PATH = os.path.join(PARENTS_PATH, f\"config/models/mf/{config_model}.yaml\")\n",
    "PREPROCESS_CONFIG_PATH = os.path.join(PARENTS_PATH, f\"config/preprocess/preprocess.yaml\")\n",
    "RESULT_PATH = os.path.join(PARENTS_PATH, f\"result/{test}/{model}/{dt}\")\n",
    "\n",
    "ROOT_PATH = os.path.join(PARENTS_PATH,'src')\n",
    "\n",
    "\n",
    "if str(ROOT_PATH) not in sys.path:\n",
    "    sys.path.append(str(ROOT_PATH))\n",
    "\n",
    "print(f\"ROOT_PATH: {ROOT_PATH}\")\n",
    "print(f\"CONFIG_PATH: {CONFIG_PATH}\")\n",
    "print(f\"PREPROCESS_CONFIG_PATH: {PREPROCESS_CONFIG_PATH}\")\n",
    "print(f\"RESULT_ROOT: {RESULT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2fc15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project imports succeeded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PROJECT_MODE = True\n",
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    from data.dataset import DataConfig, DatasetLoader\n",
    "    from evaluation.metric_calculator import MostPopularMetricCalculator\n",
    "    from tools.config import load_yaml\n",
    "    from tools.logger import common_logging, setup_logger\n",
    "    from tools.parse_args import save_command_to_file\n",
    "    from tools.utils import haversine\n",
    "    print(\"Project imports succeeded.\")\n",
    "except Exception as e:\n",
    "    PROJECT_MODE = False\n",
    "    print(\"Project imports failed.\")\n",
    "    print(\"Reason:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358081c4",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afdf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_region_label(addr: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract a region label (e.g., '서울시 강남구') from a road address string.\n",
    "\n",
    "    Args:\n",
    "        addr (str): Address string.\n",
    "\n",
    "    Returns:\n",
    "        str: Region label extracted from the address.\n",
    "             - If the second token ends with '구', returns first two tokens joined.\n",
    "             - If matches '군', '구', '시', returns the matched group.\n",
    "             - Otherwise returns the first token.\n",
    "             - Returns 'unknown' if input is invalid or empty.\n",
    "    \"\"\"\n",
    "    if not isinstance(addr, str) or not addr:\n",
    "        return \"unknown\"\n",
    "    parts = addr.split()\n",
    "    if len(parts) >= 2 and parts[1].endswith(\"구\"):\n",
    "        return \" \".join(parts[:2])\n",
    "    m = re.match(r\"^(\\S+)\\s+(\\S+구|\\S+군|\\S+시)\", addr)\n",
    "    return m.group(0) if m else parts[0] if parts else \"unknown\"\n",
    "\n",
    "\n",
    "def _minmax(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply min-max normalization to an array.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Input array.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Normalized array scaled to [0, 1].\n",
    "                    Returns zeros if input has no variation.\n",
    "    \"\"\"\n",
    "    x = x.astype(np.float32, copy=False)\n",
    "    mn, mx = float(x.min()), float(x.max())\n",
    "    return (x - mn) / (mx - mn + 1e-8) if mx > mn else np.zeros_like(x, dtype=np.float32)\n",
    "\n",
    "\n",
    "def _validate_and_clip_k(item_ids: np.ndarray, base_scores: np.ndarray, k: int) -> int:\n",
    "    \"\"\"\n",
    "    Validate and clip k to be within the valid range of candidate items.\n",
    "\n",
    "    Args:\n",
    "        item_ids (np.ndarray): Candidate item IDs.\n",
    "        base_scores (np.ndarray): Base scores corresponding to item_ids.\n",
    "        k (int): Requested number of items.\n",
    "\n",
    "    Returns:\n",
    "        int: Clipped value of k (0 if no items or invalid input).\n",
    "    \"\"\"\n",
    "    assert len(item_ids) == len(base_scores), \"item_ids/base_scores length mismatch\"\n",
    "    L = len(item_ids)\n",
    "    return 0 if (L == 0 or k <= 0) else min(k, L)\n",
    "\n",
    "\n",
    "def _prepare_meta(item_meta: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[int, int]]:\n",
    "    \"\"\"\n",
    "    Prepare metadata for items and build an index mapping.\n",
    "\n",
    "    Args:\n",
    "        item_meta (pd.DataFrame): DataFrame containing diner metadata.\n",
    "                                  Required columns: diner_idx, diner_category_large,\n",
    "                                  diner_lat, diner_lon.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, Dict[int, int]]:\n",
    "            - Cleaned metadata DataFrame (unique diner_idx).\n",
    "            - Mapping from diner_idx to row index.\n",
    "    \"\"\"\n",
    "    required = {\"diner_idx\", \"diner_category_large\", \"diner_lat\", \"diner_lon\"}\n",
    "    missing = required - set(item_meta.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"item_meta missing columns: {missing}\")\n",
    "    meta = (\n",
    "        item_meta[[\"diner_idx\", \"diner_category_large\", \"diner_lat\", \"diner_lon\"]]\n",
    "        .drop_duplicates(\"diner_idx\").reset_index(drop=True)\n",
    "    )\n",
    "    id2row = {int(r.diner_idx): i for i, r in meta.iterrows()}\n",
    "    return meta, id2row\n",
    "\n",
    "\n",
    "def _filter_candidates_by_meta_and_topm(\n",
    "    item_ids: np.ndarray,\n",
    "    rel: np.ndarray,\n",
    "    id2row: Dict[int, int],\n",
    "    top_m: Optional[int],\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Filter candidate items by available metadata and optionally keep only top-M by relevance.\n",
    "\n",
    "    Args:\n",
    "        item_ids (np.ndarray): Candidate item IDs.\n",
    "        rel (np.ndarray): Relevance scores for items.\n",
    "        id2row (Dict[int, int]): Mapping from diner_idx to row index.\n",
    "        top_m (Optional[int]): If set, keep only top-M items by relevance.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "            - Filtered item IDs.\n",
    "            - Corresponding relevance scores.\n",
    "            - Row indices in metadata DataFrame.\n",
    "    \"\"\"\n",
    "    has_meta = np.fromiter((int(x) in id2row for x in item_ids), dtype=bool, count=len(item_ids))\n",
    "    item_ids = item_ids[has_meta]\n",
    "    rel = rel[has_meta]\n",
    "    if item_ids.size == 0:\n",
    "        return item_ids, rel, np.array([], dtype=int)\n",
    "\n",
    "    if top_m is not None and top_m < item_ids.size:\n",
    "        top_idx = np.argpartition(-rel, kth=top_m - 1)[:top_m]\n",
    "        item_ids = item_ids[top_idx]\n",
    "        rel = rel[top_idx]\n",
    "\n",
    "    rows = np.fromiter((id2row[int(cid)] for cid in item_ids), dtype=int, count=item_ids.size)\n",
    "    return item_ids, rel, rows\n",
    "\n",
    "\n",
    "def _encode_categories(meta_sorted: pd.DataFrame) -> Tuple[np.ndarray, pd.Series]:\n",
    "    \"\"\"\n",
    "    Encode categorical labels of diners into numeric codes.\n",
    "\n",
    "    Args:\n",
    "        meta_sorted (pd.DataFrame): Metadata DataFrame sorted to match candidates.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, pd.Series]:\n",
    "            - Category codes as integers.\n",
    "            - Original category labels as pandas Series.\n",
    "    \"\"\"\n",
    "    cats = meta_sorted[\"diner_category_large\"].astype(\"category\")\n",
    "    cat_codes = cats.cat.codes.to_numpy(dtype=np.int32)\n",
    "    return cat_codes, cats\n",
    "\n",
    "\n",
    "def _geo_precompute(meta_sorted: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Precompute geographic values for efficiency.\n",
    "\n",
    "    Args:\n",
    "        meta_sorted (pd.DataFrame): Metadata DataFrame containing diner_lat, diner_lon.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "            - Latitudes in radians.\n",
    "            - Longitudes in radians.\n",
    "            - Cosine of latitudes.\n",
    "    \"\"\"\n",
    "    lat_rad = np.deg2rad(meta_sorted[\"diner_lat\"].to_numpy(dtype=np.float32)).astype(np.float32)\n",
    "    lon_rad = np.deg2rad(meta_sorted[\"diner_lon\"].to_numpy(dtype=np.float32)).astype(np.float32)\n",
    "    cos_lat = np.cos(lat_rad).astype(np.float32)\n",
    "    return (np.ascontiguousarray(lat_rad),\n",
    "            np.ascontiguousarray(lon_rad),\n",
    "            np.ascontiguousarray(cos_lat))\n",
    "\n",
    "\n",
    "def _build_coverage_labels(\n",
    "    item_ids: np.ndarray,\n",
    "    cats: pd.Series,\n",
    "    region_of: Optional[Dict[int, str]],\n",
    ") -> Tuple[List[List[str]], Dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Build coverage labels for items (category + region) and index mapping.\n",
    "\n",
    "    Args:\n",
    "        item_ids (np.ndarray): Candidate item IDs.\n",
    "        cats (pd.Series): Category labels for items.\n",
    "        region_of (Optional[Dict[int, str]]): Mapping from item_id to region label.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[List[str]], Dict[str, np.ndarray]]:\n",
    "            - List of labels per item (category + region).\n",
    "            - Dictionary mapping label -> array of indices having that label.\n",
    "    \"\"\"\n",
    "    region_of = region_of or {}\n",
    "    categories_str = cats.astype(str).to_numpy()\n",
    "    regions = np.array([region_of.get(int(cid), \"unknown\") for cid in item_ids], dtype=object)\n",
    "\n",
    "    lab_cat = np.array([f\"diner_category_large:{v}\" for v in categories_str], dtype=object)\n",
    "    lab_reg = np.array([f\"diner_road_address:{r}\" for r in regions], dtype=object)\n",
    "    labels_by_idx = [[lab_cat[i], lab_reg[i]] for i in range(item_ids.size)]\n",
    "\n",
    "    label_to_indices: Dict[str, np.ndarray] = {}\n",
    "    for lab in np.unique(lab_cat):\n",
    "        label_to_indices[lab] = np.flatnonzero(lab_cat == lab)\n",
    "    for lab in np.unique(lab_reg):\n",
    "        label_to_indices[lab] = np.flatnonzero(lab_reg == lab)\n",
    "    return labels_by_idx, label_to_indices\n",
    "\n",
    "\n",
    "def _apply_coverage_max_candonly(\n",
    "    cand_idx: np.ndarray,\n",
    "    cov_counts: Dict[str, int],\n",
    "    coverage_max: Dict[str, int],\n",
    "    label_to_indices: Dict[str, np.ndarray],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply coverage_max constraint to filter out candidates exceeding maximum quota.\n",
    "\n",
    "    Args:\n",
    "        cand_idx (np.ndarray): Indices of candidate items.\n",
    "        cov_counts (Dict[str, int]): Current coverage counts per label.\n",
    "        coverage_max (Dict[str, int]): Maximum allowed counts per label.\n",
    "        label_to_indices (Dict[str, np.ndarray]): Label-to-indices mapping.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Filtered candidate indices.\n",
    "    \"\"\"\n",
    "    if not coverage_max or cand_idx.size == 0:\n",
    "        return cand_idx\n",
    "    cand_mask = np.ones(cand_idx.size, dtype=bool)\n",
    "    idx_in_cand = {int(i): pos for pos, i in enumerate(cand_idx)}\n",
    "    for lab, mx in coverage_max.items():\n",
    "        if mx is None:\n",
    "            continue\n",
    "        if cov_counts.get(lab, 0) >= mx:\n",
    "            idxs = label_to_indices.get(lab)\n",
    "            if idxs is None or idxs.size == 0:\n",
    "                continue\n",
    "            for i in idxs:\n",
    "                pos = idx_in_cand.get(int(i))\n",
    "                if pos is not None:\n",
    "                    cand_mask[pos] = False\n",
    "    return cand_idx[cand_mask]\n",
    "\n",
    "\n",
    "def _coverage_min_bonus_candonly(\n",
    "    cand_idx: np.ndarray,\n",
    "    cov_counts: Dict[str, int],\n",
    "    coverage_min: Dict[str, int],\n",
    "    label_to_indices: Dict[str, np.ndarray],\n",
    "    step: float = 0.05,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute bonus scores for candidates based on coverage_min deficits.\n",
    "\n",
    "    Args:\n",
    "        cand_idx (np.ndarray): Indices of candidate items.\n",
    "        cov_counts (Dict[str, int]): Current coverage counts per label.\n",
    "        coverage_min (Dict[str, int]): Minimum desired counts per label.\n",
    "        label_to_indices (Dict[str, np.ndarray]): Label-to-indices mapping.\n",
    "        step (float): Bonus increment per deficit unit.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Bonus values for candidates.\n",
    "    \"\"\"\n",
    "    if not coverage_min or cand_idx.size == 0:\n",
    "        return np.zeros(cand_idx.size, dtype=np.float32)\n",
    "    bonus = np.zeros(cand_idx.size, dtype=np.float32)\n",
    "    idx_in_cand = {int(i): pos for pos, i in enumerate(cand_idx)}\n",
    "    for lab, mn in coverage_min.items():\n",
    "        deficit = mn - cov_counts.get(lab, 0)\n",
    "        if deficit <= 0:\n",
    "            continue\n",
    "        idxs = label_to_indices.get(lab)\n",
    "        if idxs is None or idxs.size == 0:\n",
    "            continue\n",
    "        for i in idxs:\n",
    "            pos = idx_in_cand.get(int(i))\n",
    "            if pos is not None:\n",
    "                bonus[pos] += deficit * step\n",
    "    return bonus\n",
    "\n",
    "\n",
    "def _geo_similarity_haversine(\n",
    "    lat_vec_rad: np.ndarray,\n",
    "    lon_vec_rad: np.ndarray,\n",
    "    sel_lat_rad: float,\n",
    "    sel_lon_rad: float,\n",
    "    tau_km: float,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute geographic similarity exp(-d/tau) using haversine distance.\n",
    "\n",
    "    Args:\n",
    "        lat_vec_rad (np.ndarray): Latitudes of candidates in radians.\n",
    "        lon_vec_rad (np.ndarray): Longitudes of candidates in radians.\n",
    "        sel_lat_rad (float): Selected latitude in radians.\n",
    "        sel_lon_rad (float): Selected longitude in radians.\n",
    "        tau_km (float): Decay parameter in kilometers.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Geographic similarity values in [0, 1].\n",
    "    \"\"\"\n",
    "    lat_deg = np.degrees(lat_vec_rad)\n",
    "    lon_deg = np.degrees(lon_vec_rad)\n",
    "    sel_lat_deg = float(np.degrees(sel_lat_rad))\n",
    "    sel_lon_deg = float(np.degrees(sel_lon_rad))\n",
    "\n",
    "    d_km = haversine(\n",
    "        reviewer_lat=sel_lat_deg,\n",
    "        reviewer_lon=sel_lon_deg,\n",
    "        diner_lat=pd.Series(lat_deg),\n",
    "        diner_lon=pd.Series(lon_deg),\n",
    "    )\n",
    "\n",
    "    inv_tau = 1.0 / max(float(tau_km), 1e-6)\n",
    "    return np.exp(-np.asarray(d_km, dtype=np.float64) * inv_tau).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 메인: MMR re-ranking (지리 유사도만 haversine 기반으로 교체) ---\n",
    "def rerank_most_popular_with_diversity(\n",
    "    item_ids: np.ndarray,\n",
    "    base_scores: np.ndarray,\n",
    "    item_meta: pd.DataFrame,\n",
    "    k: int,\n",
    "    lambda_div: float = 0.55,      \n",
    "    w_cat: float = 0.5,\n",
    "    w_geo: float = 0.5,\n",
    "    geo_tau_km: float = 2.0,\n",
    "    coverage_min: Optional[Dict[str, int]] = None,\n",
    "    coverage_max: Optional[Dict[str, int]] = None,\n",
    "    region_of: Optional[Dict[int, str]] = None,\n",
    "    popularity_weight: float = 0.0,\n",
    "    popularity_scores: Optional[np.ndarray] = None,\n",
    "    normalize_rel: bool = True,\n",
    "    top_m: Optional[int] = None,         \n",
    "    debug: bool = False,\n",
    "    prefix_freeze: int = 0,               \n",
    "    coverage_step: float = 0.05,          \n",
    "):\n",
    "    \"\"\"\n",
    "    Re-rank the Most Popular recommendation list with category and geographic diversity\n",
    "    using a Maximal Marginal Relevance (MMR) approach.\n",
    "\n",
    "    The final score of a candidate item i is computed as:\n",
    "        score(i) = λ · rel(i) - (1-λ) · sim_max(i) + bonus(i)\n",
    "    where:\n",
    "        - rel(i): normalized relevance (optionally blended with popularity)\n",
    "        - sim_max(i): maximum similarity to already selected items\n",
    "          sim(i,j) = w_cat * [cat(i) = cat(j)] + w_geo * exp(-d(i,j)/τ)\n",
    "          with d(i,j) the haversine distance in km and τ = geo_tau_km\n",
    "        - bonus(i): additional bonus to encourage coverage_min constraints\n",
    "\n",
    "    Args:\n",
    "        item_ids (np.ndarray): Array of candidate item IDs.\n",
    "        base_scores (np.ndarray): Base relevance scores for each item.\n",
    "        item_meta (pd.DataFrame): Metadata with required columns:\n",
    "            ['diner_idx', 'diner_category_large', 'diner_lat', 'diner_lon'].\n",
    "        k (int): Number of items to select.\n",
    "        lambda_div (float, optional): Trade-off parameter (λ↑ → accuracy↑, diversity↓).\n",
    "        w_cat (float, optional): Weight for category similarity.\n",
    "        w_geo (float, optional): Weight for geographic similarity.\n",
    "        geo_tau_km (float, optional): Decay parameter (km) for geographic similarity kernel.\n",
    "        coverage_min (Optional[Dict[str, int]], optional): Minimum coverage requirements per label.\n",
    "        coverage_max (Optional[Dict[str, int]], optional): Maximum coverage limits per label.\n",
    "        region_of (Optional[Dict[int, str]], optional): Mapping from item_id to region label.\n",
    "        popularity_weight (float, optional): Weight for blending relevance with popularity.\n",
    "        popularity_scores (Optional[np.ndarray], optional): Popularity scores for items.\n",
    "        normalize_rel (bool, optional): Whether to min-max normalize relevance.\n",
    "        top_m (Optional[int], optional): Pre-select top-M items by relevance before re-ranking.\n",
    "        debug (bool, optional): If True, print simple debug info during first steps.\n",
    "        prefix_freeze (int, optional): Keep top-T original items fixed in the final ranking.\n",
    "        use_geo_fast (bool, optional): Legacy flag (ignored).\n",
    "        coverage_step (float, optional): Step size for coverage_min bonus increments.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]:\n",
    "            - Selected item IDs (length k).\n",
    "            - (Currently empty) array for scores, placeholder for extension.\n",
    "    \"\"\"\n",
    "\n",
    "    k = _validate_and_clip_k(item_ids, base_scores, k)\n",
    "    if k == 0:\n",
    "        return np.array([], dtype=int), np.array([], dtype=float)\n",
    "\n",
    "    base_scores = np.asarray(item_ids, dtype=np.int64) * 0 + np.asarray(base_scores, dtype=np.float32)  # ensure same length\n",
    "    rel = base_scores.astype(np.float32, copy=True)\n",
    "    if normalize_rel:\n",
    "        rel = _minmax(rel)\n",
    "    if popularity_scores is not None:\n",
    "        pop = np.asarray(popularity_scores, dtype=np.float32)\n",
    "        if normalize_rel:\n",
    "            pop = _minmax(pop)\n",
    "        rel = (1 - popularity_weight) * rel + popularity_weight * pop\n",
    "\n",
    "    lam = float(np.clip(lambda_div, 0.0, 1.0))\n",
    "    rel_n = _minmax(rel)  # 루프 밖 1회\n",
    "\n",
    "    meta, id2row = _prepare_meta(item_meta)\n",
    "    item_ids_f, rel_f, rows = _filter_candidates_by_meta_and_topm(item_ids, rel_n, id2row, top_m)\n",
    "    if item_ids_f.size == 0:\n",
    "        return np.array([], dtype=int), np.array([], dtype=float)\n",
    "\n",
    "    meta_sorted = meta.iloc[rows]\n",
    "    cat_codes, cats = _encode_categories(meta_sorted)\n",
    "    lat_rad, lon_rad, _cos_lat_unused = _geo_precompute(meta_sorted)\n",
    "    labels_by_idx, label_to_indices = _build_coverage_labels(item_ids_f, cats, region_of)\n",
    "\n",
    "    T = int(max(0, min(prefix_freeze, k, item_ids_f.size)))\n",
    "    frozen_ids = item_ids_f[:T].astype(int, copy=False)\n",
    "    size = item_ids_f.size\n",
    "    alive = np.ones(size, dtype=bool)\n",
    "    alive[:T] = False\n",
    "\n",
    "    coverage_min = coverage_min or {}\n",
    "    coverage_max = coverage_max or {}\n",
    "    cov_counts: Dict[str, int] = {}\n",
    "    for i in range(T):\n",
    "        for lab in labels_by_idx[i]:\n",
    "            cov_counts[lab] = cov_counts.get(lab, 0) + 1\n",
    "\n",
    "    current_max_sim = np.zeros(size, dtype=np.float32)\n",
    "    if T > 0 and alive.any():\n",
    "        aidx = np.flatnonzero(alive)\n",
    "        for sel in range(T):\n",
    "            sel_code = cat_codes[sel]\n",
    "            sel_lat = float(lat_rad[sel]); sel_lon = float(lon_rad[sel])\n",
    "\n",
    "            sim_cat = (cat_codes[aidx] == sel_code).astype(np.float32)\n",
    "            sim_geo = _geo_similarity_haversine(\n",
    "                lat_vec_rad=lat_rad[aidx],\n",
    "                lon_vec_rad=lon_rad[aidx],\n",
    "                sel_lat_rad=sel_lat,\n",
    "                sel_lon_rad=sel_lon,\n",
    "                tau_km=geo_tau_km,\n",
    "            )\n",
    "            combined = (w_cat * sim_cat + w_geo * sim_geo).astype(np.float32)\n",
    "            np.maximum(current_max_sim[aidx], combined, out=current_max_sim[aidx])\n",
    "\n",
    "    chosen_ids: List[int] = [] if T == 0 else list(frozen_ids)\n",
    "    chosen_scores: List[float] = []  # MMR 점수도 기록용\n",
    "\n",
    "    step = 0\n",
    "    while len(chosen_ids) < k and alive.any():\n",
    "        cand_idx = np.flatnonzero(alive)\n",
    "        if cand_idx.size == 0:\n",
    "            break\n",
    "\n",
    "        cand_idx = _apply_coverage_max_candonly(\n",
    "            cand_idx=cand_idx,\n",
    "            cov_counts=cov_counts,\n",
    "            coverage_max=coverage_max,\n",
    "            label_to_indices=label_to_indices,\n",
    "        )\n",
    "        if cand_idx.size == 0:\n",
    "            break\n",
    "\n",
    "        bonus_c = _coverage_min_bonus_candonly(\n",
    "            cand_idx=cand_idx,\n",
    "            cov_counts=cov_counts,\n",
    "            coverage_min=coverage_min,\n",
    "            label_to_indices=label_to_indices,\n",
    "            step=coverage_step,\n",
    "        )\n",
    "\n",
    "        sim_c = current_max_sim[cand_idx]\n",
    "        mn, mx = float(sim_c.min()), float(sim_c.max())\n",
    "        sim_c_n = (sim_c - mn) / (mx - mn + 1e-8) if mx > mn else np.zeros_like(sim_c, dtype=np.float32)\n",
    "\n",
    "        mmr = lam * rel_n[cand_idx] - (1.0 - lam) * sim_c_n + bonus_c\n",
    "        best_local = int(np.argmax(mmr))\n",
    "        best_idx = int(cand_idx[best_local])\n",
    "\n",
    "        chosen_ids.append(int(item_ids_f[best_idx]))\n",
    "        alive[best_idx] = False\n",
    "\n",
    "        for lab in labels_by_idx[best_idx]:\n",
    "            cov_counts[lab] = max(0, cov_counts.get(lab, 0)) + 1\n",
    "\n",
    "        if alive.any():\n",
    "            sel_code = cat_codes[best_idx]\n",
    "            sel_lat = float(lat_rad[best_idx]); sel_lon = float(lon_rad[best_idx])\n",
    "            aidx = np.flatnonzero(alive)\n",
    "\n",
    "            sim_cat = (cat_codes[aidx] == sel_code).astype(np.float32)\n",
    "            sim_geo = _geo_similarity_haversine(\n",
    "                lat_vec_rad=lat_rad[aidx],\n",
    "                lon_vec_rad=lon_rad[aidx],\n",
    "                sel_lat_rad=sel_lat,\n",
    "                sel_lon_rad=sel_lon,\n",
    "                tau_km=geo_tau_km,\n",
    "            )\n",
    "            combined = (w_cat * sim_cat + w_geo * sim_geo).astype(np.float32)\n",
    "            np.maximum(current_max_sim[aidx], combined, out=current_max_sim[aidx])\n",
    "\n",
    "        if debug and step in (0, 1):\n",
    "            ci = np.flatnonzero(alive)\n",
    "            if ci.size:\n",
    "                print(f\"[step {step}] penalty.std={current_max_sim[ci].std():.5f}\")\n",
    "        step += 1\n",
    "\n",
    "    return np.array(chosen_ids[:k], dtype=int), np.array([], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c3d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_region_periphery(\n",
    "    item_ids: np.ndarray,\n",
    "    base_scores: np.ndarray,\n",
    "    item_meta_std: pd.DataFrame,\n",
    "    k: int,\n",
    "    region_label: str = \"서울 강남구\",\n",
    "    hotspot_coords: Optional[Iterable[Tuple[float, float]]] = None,\n",
    "    n_auto_hotspots: int = 5,\n",
    "    periphery_strength: float = 0.5,\n",
    "    periphery_cap: float = 0.15,\n",
    "    lambda_div: float = 0.55,\n",
    "    w_cat: float = 0.5,\n",
    "    w_geo: float = 0.5,\n",
    "    geo_tau_km: float = 2.0,\n",
    "    coverage_min: Optional[Dict[str, int]] = None,\n",
    "    coverage_max: Optional[Dict[str, int]] = None,\n",
    "    region_of: Optional[Dict[int, str]] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Re-rank items within a target region by adding a periphery bonus (farther from hotspots)\n",
    "    and then applying MMR-based re-ranking with category/geography diversity.\n",
    "\n",
    "    The periphery bonus is computed by:\n",
    "      1) Determining hotspot centers (given or auto via KMeans).\n",
    "      2) Computing each candidate's minimum haversine distance to the centers.\n",
    "      3) Min-max normalizing that minimum distance and scaling/clipping to [0, periphery_cap].\n",
    "      4) Adding the bonus to base_scores before calling MMR re-ranking.\n",
    "\n",
    "    Args:\n",
    "        item_ids (np.ndarray): Array of candidate item IDs (ordered by base ranking).\n",
    "        base_scores (np.ndarray): Base relevance scores aligned with item_ids.\n",
    "        item_meta_std (pd.DataFrame): Metadata containing at least:\n",
    "            ['diner_idx', 'diner_lat', 'diner_lon', 'diner_road_address'].\n",
    "        k (int): Number of items to select.\n",
    "        region_label (str, optional): Target region label (e.g., \"서울 강남구\").\n",
    "        hotspot_coords (Optional[Iterable[Tuple[float, float]]], optional):\n",
    "            Iterable of (lat, lon) hotspot coordinates in degrees. If None, auto-detected.\n",
    "        n_auto_hotspots (int, optional): Number of clusters (hotspots) to auto-detect via KMeans when not provided.\n",
    "        periphery_strength (float, optional): Scale for the periphery bonus before capping.\n",
    "        periphery_cap (float, optional): Upper cap applied to the periphery bonus.\n",
    "        lambda_div (float, optional): MMR trade-off between relevance and diversity [0, 1].\n",
    "        w_cat (float, optional): Weight for category similarity in MMR.\n",
    "        w_geo (float, optional): Weight for geographic similarity in MMR.\n",
    "        geo_tau_km (float, optional): Length scale (km) for geographic similarity kernel.\n",
    "        coverage_min (Optional[Dict[str, int]], optional): Minimum coverage constraints per label.\n",
    "        coverage_max (Optional[Dict[str, int]], optional): Maximum coverage constraints per label.\n",
    "        region_of (Optional[Dict[int, str]], optional): Mapping from item_id to region label (used by MMR coverage).\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]:\n",
    "            - Selected item IDs (length ≤ k).\n",
    "            - Placeholder scores array (currently empty).\n",
    "    \"\"\"\n",
    "    # 0) 기본 변환\n",
    "    item_ids = np.asarray(item_ids, dtype=np.int64)\n",
    "    base_scores = np.asarray(base_scores, dtype=np.float32)\n",
    "    meta = item_meta_std\n",
    "\n",
    "    # 1) 지역 필터\n",
    "    target_region = extract_region_label(region_label)\n",
    "    if \"diner_road_address\" in meta.columns:\n",
    "        region_norm = meta[\"diner_road_address\"].map(extract_region_label)\n",
    "        region_idx = meta.loc[region_norm == target_region, \"diner_idx\"].to_numpy(dtype=np.int64, copy=False)\n",
    "    else:\n",
    "        region_idx = np.empty(0, dtype=np.int64)\n",
    "\n",
    "    if region_idx.size > 0:\n",
    "        mask = np.isin(item_ids, region_idx, assume_unique=False)\n",
    "        item_ids_g = item_ids[mask]\n",
    "        base_scores_g = base_scores[mask]\n",
    "    else:\n",
    "        # 필터 결과가 0이면 원본 전체 후보 사용\n",
    "        item_ids_g = item_ids\n",
    "        base_scores_g = base_scores\n",
    "\n",
    "    if item_ids_g.size == 0 or k <= 0:\n",
    "        return item_ids[:0], base_scores[:0]\n",
    "\n",
    "    # 2) 좌표 정리\n",
    "    meta_idx = meta.set_index(\"diner_idx\", drop=False)\n",
    "    latlon = meta_idx.reindex(item_ids_g)[[\"diner_lat\", \"diner_lon\"]].to_numpy(dtype=np.float32)\n",
    "    valid = np.isfinite(latlon).all(axis=1)\n",
    "    latlon_valid = latlon[valid]\n",
    "\n",
    "    # 3) 핫스팟 결정 (주어지지 않으면 KMeans로 자동 산출)\n",
    "    if hotspot_coords is None and n_auto_hotspots > 0 and latlon_valid.shape[0] >= 2:\n",
    "        from sklearn.cluster import KMeans\n",
    "        n_clusters = int(min(n_auto_hotspots, latlon_valid.shape[0]))\n",
    "        km = KMeans(n_clusters=n_clusters, n_init=5, random_state=42)\n",
    "        km.fit(latlon_valid)\n",
    "        centers = km.cluster_centers_.astype(np.float32, copy=False)   # degrees\n",
    "    elif hotspot_coords is not None:\n",
    "        centers = np.asarray(list(hotspot_coords), dtype=np.float32)   # degrees\n",
    "    else:\n",
    "        centers = np.empty((0, 2), dtype=np.float32)\n",
    "\n",
    "    # 4) 변두리 보너스 (정확한 거리: haversine 사용)\n",
    "    periphery_bonus = np.zeros_like(base_scores_g, dtype=np.float32)\n",
    "    if centers.size and latlon_valid.shape[0] > 0 and periphery_strength > 0 and periphery_cap > 0:\n",
    "        # centers: shape (Nc, 2) in degrees; latlon_valid: (Nv, 2) in degrees\n",
    "        # 각 center에 대해 haversine(center, 모든 valid 후보) → (Nv, Nc) 거리 행렬 후 min\n",
    "        dists_stack = []\n",
    "        diner_lat_series = pd.Series(latlon_valid[:, 0], copy=False)\n",
    "        diner_lon_series = pd.Series(latlon_valid[:, 1], copy=False)\n",
    "        for c_lat, c_lon in centers:\n",
    "            d_km = haversine(\n",
    "                reviewer_lat=float(c_lat),\n",
    "                reviewer_lon=float(c_lon),\n",
    "                diner_lat=diner_lat_series,\n",
    "                diner_lon=diner_lon_series,\n",
    "            )  # (Nv,)\n",
    "            dists_stack.append(np.asarray(d_km, dtype=np.float64))\n",
    "        if dists_stack:\n",
    "            D = np.vstack(dists_stack).T  # (Nv, Nc)\n",
    "            dmin = D.min(axis=1).astype(np.float32, copy=False)\n",
    "            # 0–1 정규화 후 가점\n",
    "            dmin_n = _minmax(dmin)  # float32, [0,1]\n",
    "            bonus_valid = np.clip(periphery_strength * dmin_n, 0.0, periphery_cap).astype(np.float32, copy=False)\n",
    "            periphery_bonus[valid] = bonus_valid  # invalid 좌표는 0 유지\n",
    "\n",
    "    base_scores_boosted = (base_scores_g + periphery_bonus).astype(np.float32, copy=False)\n",
    "\n",
    "    # 5) 최종 MMR 재랭크 호출\n",
    "    use_geo = float(np.isfinite(latlon).sum()) >= 2.0\n",
    "    final_ids, final_scores = rerank_most_popular_with_diversity(\n",
    "        item_ids=item_ids_g,\n",
    "        base_scores=base_scores_boosted,\n",
    "        item_meta=meta,\n",
    "        k=k,\n",
    "        lambda_div=lambda_div,\n",
    "        w_cat=w_cat,\n",
    "        w_geo=w_geo if use_geo else 0.0,\n",
    "        geo_tau_km=geo_tau_km,\n",
    "        coverage_min=coverage_min,\n",
    "        coverage_max=coverage_max,\n",
    "        region_of=region_of,\n",
    "        popularity_weight=0.0,\n",
    "        popularity_scores=None,\n",
    "        normalize_rel=True,\n",
    "        top_m=None,\n",
    "        debug=False,\n",
    "    )\n",
    "    return final_ids, final_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a45ff5",
   "metadata": {},
   "source": [
    "\n",
    "## Project Mode (Main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912ed49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-25 00:30:28,739 - yamyam - INFO - model: most_popular\n",
      "2025-08-25 00:30:28,740 - yamyam - INFO - training results will be saved in C:\\Users\\LEEYS\\Desktop\\yamyam-lab\\result\\untest\\most_popular\\20250825003028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 data가 존재합니다. 파일 경로를 반환합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-25 00:37:17,966 - preprocess.filter - INFO - Token time for tokenizing: 369.46\n",
      "2025-08-25 00:37:19,455 - preprocess.filter - INFO - Detected 10 diner_ids with abusive reviews: [20557155.0, 561814157.0, 717255023.0, 1210281986.0, 1210386151.0, 1275807781.0, 1390211388.0, 1420824177.0, 1567102742.0, 1983344097.0]\n",
      "2025-08-25 00:37:19,686 - preprocess.filter - INFO - Excluded 3204 abusive reviews\n",
      "2025-08-25 00:37:22,552 - yamyam - INFO - train dataset period: 2024-09-01 <= dt < 2024-12-01\n",
      "2025-08-25 00:37:22,553 - yamyam - INFO - val dataset period: 2024-12-01 <= dt < 2025-01-01\n",
      "2025-08-25 00:37:22,554 - yamyam - INFO - test dataset period: 2025-01-01 <= dt < 2025-02-01\n",
      "2025-08-25 00:37:22,555 - yamyam - INFO - ######## Number of reviews statistics ########\n",
      "2025-08-25 00:37:22,555 - yamyam - INFO - Number of reviews in train: 666811\n",
      "2025-08-25 00:37:22,556 - yamyam - INFO - Number of reviews in val: 666811\n",
      "2025-08-25 00:37:22,561 - yamyam - INFO - Number of reviews in test: 666811\n",
      "2025-08-25 00:37:22,562 - yamyam - INFO - ######## Train data statistics ########\n",
      "2025-08-25 00:37:22,562 - yamyam - INFO - Number of users in train: 94799\n",
      "2025-08-25 00:37:22,563 - yamyam - INFO - Number of diners in train: 71281\n",
      "2025-08-25 00:37:22,563 - yamyam - INFO - Number of feedbacks in train: 666811\n",
      "2025-08-25 00:37:22,564 - yamyam - INFO - Train data density: 0.0099%\n",
      "2025-08-25 00:37:22,566 - yamyam - INFO - ######## Validation data statistics ########\n",
      "2025-08-25 00:37:22,566 - yamyam - INFO - Number of users in val: 35225\n",
      "2025-08-25 00:37:22,567 - yamyam - INFO - Number of diners in val: 33142\n",
      "2025-08-25 00:37:22,568 - yamyam - INFO - Number of feedbacks in val: 666811\n",
      "2025-08-25 00:37:22,569 - yamyam - INFO - Validation data density: 0.0571%\n",
      "2025-08-25 00:37:22,570 - yamyam - INFO - ######## Test data statistics ########\n",
      "2025-08-25 00:37:22,570 - yamyam - INFO - Number of users in test: 36037\n",
      "2025-08-25 00:37:22,571 - yamyam - INFO - Number of diners in test: 34788\n",
      "2025-08-25 00:37:22,571 - yamyam - INFO - Number of feedbacks in test: 666811\n",
      "2025-08-25 00:37:22,572 - yamyam - INFO - Test data density: 0.0532%\n",
      "2025-08-25 00:37:22,573 - yamyam - INFO - ######## Warm / Cold users analysis in validation and test dataset ########\n",
      "2025-08-25 00:37:22,592 - yamyam - INFO - Number of users within train, but not in val: 83994\n",
      "2025-08-25 00:37:22,611 - yamyam - INFO - Number of users within train, but not in test: 84347\n",
      "2025-08-25 00:37:22,611 - yamyam - INFO - Number of warm start users in val: 10805\n",
      "2025-08-25 00:37:22,613 - yamyam - INFO - Number of cold start users in val: 24420\n",
      "2025-08-25 00:37:22,614 - yamyam - INFO - Number of warm start users in test: 10452\n",
      "2025-08-25 00:37:22,615 - yamyam - INFO - Number of cold start users in test: 25585\n",
      "  File \"c:\\Users\\LEEYS\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\src-fg4b1aLu-py3.12\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEEYS\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\LEEYS\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\LEEYS\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "2025-08-25 00:37:28,646 - yamyam - INFO - ################################ Validation data metric report ################################\n",
      "2025-08-25 00:37:28,647 - yamyam - INFO - [ warm users metric report calculated from val data ]\n",
      "2025-08-25 00:37:28,648 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:37:28,649 - yamyam - INFO - map result: 0.0003|0.00031|0.00032|0.00036\n",
      "2025-08-25 00:37:28,650 - yamyam - INFO - ndcg result: 0.00038|0.00039|0.00044|0.00061\n",
      "2025-08-25 00:37:28,650 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:37:28,651 - yamyam - INFO - recall: 0.00765|0.01049|0.01049|0.01049|0.01049\n",
      "2025-08-25 00:37:28,652 - yamyam - INFO - [ cold users metric report calculated from val data ]\n",
      "2025-08-25 00:37:28,652 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:37:28,653 - yamyam - INFO - map result: 0.00169|0.00172|0.00172|0.00177\n",
      "2025-08-25 00:37:28,654 - yamyam - INFO - ndcg result: 0.00185|0.00191|0.00192|0.00211\n",
      "2025-08-25 00:37:28,655 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:37:28,655 - yamyam - INFO - recall: 0.00888|0.0108|0.0108|0.0108|0.0108\n",
      "2025-08-25 00:37:28,656 - yamyam - INFO - [ all users metric report calculated from val data ]\n",
      "2025-08-25 00:37:28,657 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:37:28,657 - yamyam - INFO - map result: 0.00126|0.00128|0.00129|0.00134\n",
      "2025-08-25 00:37:28,659 - yamyam - INFO - ndcg result: 0.0014|0.00145|0.00147|0.00165\n",
      "2025-08-25 00:37:28,659 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:37:28,660 - yamyam - INFO - recall: 0.0085|0.0107|0.0107|0.0107|0.0107\n",
      "2025-08-25 00:37:29,823 - yamyam - INFO - ################################ Test data metric report ################################\n",
      "2025-08-25 00:37:29,824 - yamyam - INFO - [ warm users metric report calculated from test data ]\n",
      "2025-08-25 00:37:29,824 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:37:29,826 - yamyam - INFO - map result: 0.00028|0.0003|0.00033|0.00038\n",
      "2025-08-25 00:37:29,827 - yamyam - INFO - ndcg result: 0.00034|0.00039|0.00049|0.00072\n",
      "2025-08-25 00:37:29,827 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:37:29,828 - yamyam - INFO - recall: 0.00776|0.00961|0.00961|0.00961|0.00961\n",
      "2025-08-25 00:37:29,828 - yamyam - INFO - [ cold users metric report calculated from test data ]\n",
      "2025-08-25 00:37:29,829 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:37:29,830 - yamyam - INFO - map result: 0.00251|0.00254|0.00254|0.00257\n",
      "2025-08-25 00:37:29,830 - yamyam - INFO - ndcg result: 0.00272|0.00277|0.00277|0.00287\n",
      "2025-08-25 00:37:29,831 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:37:29,832 - yamyam - INFO - recall: 0.0113|0.01506|0.01506|0.01506|0.01506\n",
      "2025-08-25 00:37:29,833 - yamyam - INFO - [ all users metric report calculated from test data ]\n",
      "2025-08-25 00:37:29,833 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:37:29,834 - yamyam - INFO - map result: 0.00187|0.00189|0.0019|0.00194\n",
      "2025-08-25 00:37:29,834 - yamyam - INFO - ndcg result: 0.00203|0.00208|0.00211|0.00224\n",
      "2025-08-25 00:37:29,836 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:37:29,836 - yamyam - INFO - recall: 0.01027|0.01348|0.01348|0.01348|0.01348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project pipeline finished. See logs for details: C:\\Users\\LEEYS\\Desktop\\yamyam-lab\\result\\untest\\most_popular\\20250825003028\\log.log\n"
     ]
    }
   ],
   "source": [
    "if PROJECT_MODE:\n",
    "    ROOT_PATH = Path(ROOT_PATH)\n",
    "    RESULT_PATH = Path(RESULT_PATH)\n",
    "\n",
    "    RESULT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    config = load_yaml(CONFIG_PATH)\n",
    "    preprocess_config = load_yaml(str(PREPROCESS_CONFIG_PATH))\n",
    "\n",
    "    # 로그 세팅 및 실행 커맨드 기록\n",
    "    file_name = config.post_training.file_name\n",
    "    logger = setup_logger(str(RESULT_PATH / file_name.log))\n",
    "    save_command_to_file(str(RESULT_PATH))\n",
    "\n",
    "    try:\n",
    "        logger.info(\"model: most_popular\")\n",
    "        logger.info(f\"training results will be saved in {RESULT_PATH}\")\n",
    "\n",
    "        # 데이터 로딩\n",
    "        fe = config.preprocess.feature_engineering\n",
    "        data_config=DataConfig(\n",
    "                X_columns=[\"diner_idx\", \"reviewer_id\"],\n",
    "                y_columns=[\"reviewer_review_score\"],\n",
    "                user_engineered_feature_names=fe.user_engineered_feature_names,\n",
    "                diner_engineered_feature_names=fe.diner_engineered_feature_names,\n",
    "                is_timeseries_by_time_point=config.preprocess.data.is_timeseries_by_time_point,\n",
    "                train_time_point=config.preprocess.data.train_time_point,\n",
    "                val_time_point=config.preprocess.data.val_time_point,\n",
    "                test_time_point=config.preprocess.data.test_time_point,\n",
    "                end_time_point=config.preprocess.data.end_time_point,\n",
    "                test=False,\n",
    "            )\n",
    "        data_config.additional_reviews_path = PARENTS_PATH / data_config.additional_reviews_path \n",
    "        data_loader = DatasetLoader(data_config = data_config)\n",
    "        data = data_loader.prepare_train_val_dataset(is_csr=True, filter_config=preprocess_config.filter)\n",
    "        common_logging(config=config, data=data, logger=logger)\n",
    "\n",
    "        # K 설정\n",
    "        top_k_values_for_pred = config.training.evaluation.top_k_values_for_pred\n",
    "        top_k_values_for_candidate = config.training.evaluation.top_k_values_for_candidate\n",
    "        top_k_values = top_k_values_for_pred + top_k_values_for_candidate\n",
    "\n",
    "        item_meta = data[\"diner_meta\"]\n",
    "        candidates = np.array(data[\"most_popular_diner_ids\"], dtype=np.int64)\n",
    "        base_scores = 1.0 / (np.arange(len(candidates)) + 1)\n",
    "\n",
    "        meta_ids = item_meta[\"diner_idx\"]\n",
    "        if not pd.api.types.is_integer_dtype(meta_ids.dtype):\n",
    "            meta_vals = pd.to_numeric(meta_ids, errors=\"coerce\").dropna().astype(np.int64).to_numpy()\n",
    "        else:\n",
    "            meta_vals = meta_ids.to_numpy(dtype=np.int64, copy=False)\n",
    "\n",
    "        mask = np.isin(candidates, meta_vals)\n",
    "        dropped = int((~mask).sum())\n",
    "        if dropped:\n",
    "            logger.warning(f\"dropped {dropped} candidates not in item_meta\")\n",
    "\n",
    "        candidates = candidates[mask]\n",
    "        base_scores = base_scores[mask]\n",
    "\n",
    "        reranked_ids, _ = rerank_region_periphery(\n",
    "            item_ids=candidates,\n",
    "            base_scores=base_scores,\n",
    "            item_meta_std=item_meta,\n",
    "            k=max(top_k_values),\n",
    "            region_label=\"서울 강남구\",\n",
    "            hotspot_coords=None,\n",
    "            n_auto_hotspots=5,      \n",
    "            periphery_strength=0.5,  \n",
    "            periphery_cap=0.15,\n",
    "            lambda_div=0.55,       \n",
    "            w_cat=0.5, w_geo=0.5,    \n",
    "            geo_tau_km=2.0,         \n",
    "        )\n",
    "        reranked_most_popular = reranked_ids.tolist()\n",
    "\n",
    "        # 평가\n",
    "        metric_calculator = MostPopularMetricCalculator(\n",
    "            top_k_values=top_k_values,\n",
    "            filter_already_liked=True,\n",
    "            recommend_batch_size=config.training.evaluation.recommend_batch_size,\n",
    "            logger=logger,\n",
    "        )\n",
    "\n",
    "        metric_dict = metric_calculator.generate_recommendations_and_calculate_metric(\n",
    "            X_train=data[\"X_train_df\"],\n",
    "            X_val_warm_users=data[\"X_val_warm_users\"],\n",
    "            X_val_cold_users=data[\"X_val_cold_users\"],\n",
    "            most_popular_diner_ids=reranked_most_popular,\n",
    "            filter_already_liked=True,\n",
    "            most_popular_rec_to_warm_users=True,\n",
    "        )\n",
    "        for user_type, metric in metric_dict.items():\n",
    "            metric_calculator.calculate_mean_metric(metric)\n",
    "        logger.info(\"################################ Validation data metric report ################################\")\n",
    "        metric_calculator.report_metric_with_warm_cold_all_users(metric_dict=metric_dict, data_type=\"val\")\n",
    "\n",
    "        metric_dict = metric_calculator.generate_recommendations_and_calculate_metric(\n",
    "            X_train=data[\"X_train_df\"],\n",
    "            X_val_warm_users=data[\"X_test_warm_users\"],\n",
    "            X_val_cold_users=data[\"X_test_cold_users\"],\n",
    "            most_popular_diner_ids=reranked_most_popular,\n",
    "            filter_already_liked=True,\n",
    "            most_popular_rec_to_warm_users=True,\n",
    "        )\n",
    "        for user_type, metric in metric_dict.items():\n",
    "            metric_calculator.calculate_mean_metric(metric)\n",
    "        logger.info(\"################################ Test data metric report ################################\")\n",
    "        metric_calculator.report_metric_with_warm_cold_all_users(metric_dict=metric_dict, data_type=\"test\")\n",
    "\n",
    "        print(\"Project pipeline finished. See logs for details:\", RESULT_PATH / file_name.log)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error during project run:\", repr(e))\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5973492",
   "metadata": {},
   "source": [
    "## 추가 실험 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e27115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-25 00:59:11,964 - yamyam - INFO - [BALANCED] generated\n",
      "2025-08-25 00:59:11,964 - yamyam - INFO - [POP_BASE] generated\n",
      "2025-08-25 00:59:15,803 - yamyam - INFO - [DIV_HEAVY] generated\n",
      "2025-08-25 00:59:15,804 - yamyam - INFO - [POP_BASE vs BALANCED] overlap@K=141/2000\n",
      "2025-08-25 00:59:15,806 - yamyam - INFO - [POP_BASE vs BALANCED] first diff at pos 0: ref=159368, var=99146\n",
      "2025-08-25 00:59:15,807 - yamyam - INFO - [POP_BASE vs BALANCED] head10 ref=[159368, 48283, 74907, 120101, 159318, 104501, 95844, 37572, 9863, 111554]\n",
      "2025-08-25 00:59:15,808 - yamyam - INFO - [POP_BASE vs BALANCED] head10 var=[99146, 115693, 4522, 62327, 125037, 126769, 6778, 131370, 48283, 51000]\n",
      "2025-08-25 00:59:15,809 - yamyam - INFO - [DIV_HEAVY vs BALANCED] overlap@K=141/2000\n",
      "2025-08-25 00:59:15,811 - yamyam - INFO - [DIV_HEAVY vs BALANCED] first diff at pos 1: ref=48283, var=135396\n",
      "2025-08-25 00:59:15,812 - yamyam - INFO - [DIV_HEAVY vs BALANCED] head10 ref=[159368, 48283, 74907, 120101, 159318, 104501, 95844, 37572, 9863, 111554]\n",
      "2025-08-25 00:59:15,812 - yamyam - INFO - [DIV_HEAVY vs BALANCED] head10 var=[159368, 135396, 120101, 144757, 94427, 93692, 159318, 78372, 142516, 121138]\n",
      "2025-08-25 00:59:16,938 - yamyam - INFO - ######## Validation metrics (BALANCED) ########\n",
      "2025-08-25 00:59:16,939 - yamyam - INFO - [ warm users metric report calculated from val data ]\n",
      "2025-08-25 00:59:16,939 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:16,940 - yamyam - INFO - map result: 0.0003|0.00031|0.00032|0.00036\n",
      "2025-08-25 00:59:16,941 - yamyam - INFO - ndcg result: 0.00038|0.00039|0.00044|0.00061\n",
      "2025-08-25 00:59:16,942 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:16,943 - yamyam - INFO - recall: 0.00765|0.01049|0.01049|0.01049|0.01049\n",
      "2025-08-25 00:59:16,943 - yamyam - INFO - [ cold users metric report calculated from val data ]\n",
      "2025-08-25 00:59:16,944 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:16,945 - yamyam - INFO - map result: 0.00169|0.00172|0.00172|0.00177\n",
      "2025-08-25 00:59:16,945 - yamyam - INFO - ndcg result: 0.00185|0.00191|0.00192|0.00211\n",
      "2025-08-25 00:59:16,946 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:16,947 - yamyam - INFO - recall: 0.00888|0.0108|0.0108|0.0108|0.0108\n",
      "2025-08-25 00:59:16,948 - yamyam - INFO - [ all users metric report calculated from val data ]\n",
      "2025-08-25 00:59:16,949 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:16,949 - yamyam - INFO - map result: 0.00126|0.00128|0.00129|0.00134\n",
      "2025-08-25 00:59:16,950 - yamyam - INFO - ndcg result: 0.0014|0.00145|0.00147|0.00165\n",
      "2025-08-25 00:59:16,951 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:16,952 - yamyam - INFO - recall: 0.0085|0.0107|0.0107|0.0107|0.0107\n",
      "2025-08-25 00:59:18,138 - yamyam - INFO - ######## Test metrics (BALANCED) ########\n",
      "2025-08-25 00:59:18,139 - yamyam - INFO - [ warm users metric report calculated from test data ]\n",
      "2025-08-25 00:59:18,140 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:18,140 - yamyam - INFO - map result: 0.00028|0.0003|0.00033|0.00038\n",
      "2025-08-25 00:59:18,142 - yamyam - INFO - ndcg result: 0.00034|0.00039|0.00049|0.00072\n",
      "2025-08-25 00:59:18,142 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:18,143 - yamyam - INFO - recall: 0.00776|0.00961|0.00961|0.00961|0.00961\n",
      "2025-08-25 00:59:18,144 - yamyam - INFO - [ cold users metric report calculated from test data ]\n",
      "2025-08-25 00:59:18,144 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:18,145 - yamyam - INFO - map result: 0.00251|0.00254|0.00254|0.00257\n",
      "2025-08-25 00:59:18,145 - yamyam - INFO - ndcg result: 0.00272|0.00277|0.00277|0.00287\n",
      "2025-08-25 00:59:18,146 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:18,147 - yamyam - INFO - recall: 0.0113|0.01506|0.01506|0.01506|0.01506\n",
      "2025-08-25 00:59:18,148 - yamyam - INFO - [ all users metric report calculated from test data ]\n",
      "2025-08-25 00:59:18,149 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:18,149 - yamyam - INFO - map result: 0.00187|0.00189|0.0019|0.00194\n",
      "2025-08-25 00:59:18,150 - yamyam - INFO - ndcg result: 0.00203|0.00208|0.00211|0.00224\n",
      "2025-08-25 00:59:18,151 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:18,152 - yamyam - INFO - recall: 0.01027|0.01348|0.01348|0.01348|0.01348\n",
      "2025-08-25 00:59:21,661 - yamyam - INFO - ######## Validation metrics (POP_BASE) ########\n",
      "2025-08-25 00:59:21,662 - yamyam - INFO - [ warm users metric report calculated from val data ]\n",
      "2025-08-25 00:59:21,663 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:21,664 - yamyam - INFO - map result: 0.00056|0.00074|0.00081|0.0012\n",
      "2025-08-25 00:59:21,664 - yamyam - INFO - ndcg result: 0.00093|0.00119|0.00139|0.00296\n",
      "2025-08-25 00:59:21,666 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:21,667 - yamyam - INFO - recall: 0.02955|0.06289|0.08304|0.11908|0.16765\n",
      "2025-08-25 00:59:21,667 - yamyam - INFO - [ cold users metric report calculated from val data ]\n",
      "2025-08-25 00:59:21,669 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:21,669 - yamyam - INFO - map result: 0.00218|0.00373|0.00404|0.00499\n",
      "2025-08-25 00:59:21,670 - yamyam - INFO - ndcg result: 0.00256|0.00567|0.0065|0.01024\n",
      "2025-08-25 00:59:21,671 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:21,671 - yamyam - INFO - recall: 0.07707|0.1165|0.13525|0.17108|0.22199\n",
      "2025-08-25 00:59:21,672 - yamyam - INFO - [ all users metric report calculated from val data ]\n",
      "2025-08-25 00:59:21,673 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:21,674 - yamyam - INFO - map result: 0.00169|0.00281|0.00305|0.00383\n",
      "2025-08-25 00:59:21,674 - yamyam - INFO - ndcg result: 0.00206|0.00429|0.00493|0.00801\n",
      "2025-08-25 00:59:21,674 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:21,676 - yamyam - INFO - recall: 0.0625|0.10005|0.11923|0.15513|0.20532\n",
      "2025-08-25 00:59:24,873 - yamyam - INFO - ######## Test metrics (POP_BASE) ########\n",
      "2025-08-25 00:59:24,874 - yamyam - INFO - [ warm users metric report calculated from test data ]\n",
      "2025-08-25 00:59:24,874 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:24,875 - yamyam - INFO - map result: 0.00078|0.00146|0.00152|0.00164\n",
      "2025-08-25 00:59:24,876 - yamyam - INFO - ndcg result: 0.00113|0.00239|0.00258|0.00306\n",
      "2025-08-25 00:59:24,877 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:24,877 - yamyam - INFO - recall: 0.01667|0.04638|0.06493|0.09614|0.1408\n",
      "2025-08-25 00:59:24,878 - yamyam - INFO - [ cold users metric report calculated from test data ]\n",
      "2025-08-25 00:59:24,878 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:24,879 - yamyam - INFO - map result: 0.00113|0.00245|0.00274|0.00336\n",
      "2025-08-25 00:59:24,880 - yamyam - INFO - ndcg result: 0.00146|0.00405|0.0048|0.00725\n",
      "2025-08-25 00:59:24,881 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:24,882 - yamyam - INFO - recall: 0.05388|0.09417|0.1127|0.14629|0.19693\n",
      "2025-08-25 00:59:24,882 - yamyam - INFO - [ all users metric report calculated from test data ]\n",
      "2025-08-25 00:59:24,883 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:24,884 - yamyam - INFO - map result: 0.00103|0.00216|0.00238|0.00286\n",
      "2025-08-25 00:59:24,885 - yamyam - INFO - ndcg result: 0.00137|0.00357|0.00416|0.00603\n",
      "2025-08-25 00:59:24,886 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:24,886 - yamyam - INFO - recall: 0.04309|0.08031|0.09885|0.13175|0.18065\n",
      "2025-08-25 00:59:25,992 - yamyam - INFO - ######## Validation metrics (DIV_HEAVY) ########\n",
      "2025-08-25 00:59:25,992 - yamyam - INFO - [ warm users metric report calculated from val data ]\n",
      "2025-08-25 00:59:25,993 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:25,994 - yamyam - INFO - map result: 0.00023|0.00028|0.00031|0.00032\n",
      "2025-08-25 00:59:25,994 - yamyam - INFO - ndcg result: 0.00024|0.00034|0.00043|0.00052\n",
      "2025-08-25 00:59:25,996 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:25,996 - yamyam - INFO - recall: 0.00712|0.01049|0.01049|0.01049|0.01049\n",
      "2025-08-25 00:59:25,998 - yamyam - INFO - [ cold users metric report calculated from val data ]\n",
      "2025-08-25 00:59:25,998 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:25,999 - yamyam - INFO - map result: 0.00157|0.00163|0.00163|0.00164\n",
      "2025-08-25 00:59:25,999 - yamyam - INFO - ndcg result: 0.0016|0.00173|0.00173|0.00177\n",
      "2025-08-25 00:59:26,000 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:26,001 - yamyam - INFO - recall: 0.00891|0.0108|0.0108|0.0108|0.0108\n",
      "2025-08-25 00:59:26,002 - yamyam - INFO - [ all users metric report calculated from val data ]\n",
      "2025-08-25 00:59:26,003 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:26,004 - yamyam - INFO - map result: 0.00116|0.00121|0.00122|0.00124\n",
      "2025-08-25 00:59:26,006 - yamyam - INFO - ndcg result: 0.00119|0.0013|0.00133|0.00139\n",
      "2025-08-25 00:59:26,007 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:26,009 - yamyam - INFO - recall: 0.00836|0.0107|0.0107|0.0107|0.0107\n",
      "2025-08-25 00:59:27,182 - yamyam - INFO - ######## Test metrics (DIV_HEAVY) ########\n",
      "2025-08-25 00:59:27,183 - yamyam - INFO - [ warm users metric report calculated from test data ]\n",
      "2025-08-25 00:59:27,184 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:27,185 - yamyam - INFO - map result: 0.00025|0.00027|0.00031|0.00035\n",
      "2025-08-25 00:59:27,186 - yamyam - INFO - ndcg result: 0.0003|0.00034|0.00044|0.00067\n",
      "2025-08-25 00:59:27,186 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:27,187 - yamyam - INFO - recall: 0.0062|0.00961|0.00961|0.00961|0.00961\n",
      "2025-08-25 00:59:27,188 - yamyam - INFO - [ cold users metric report calculated from test data ]\n",
      "2025-08-25 00:59:27,189 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:27,190 - yamyam - INFO - map result: 0.00224|0.00233|0.00234|0.00236\n",
      "2025-08-25 00:59:27,190 - yamyam - INFO - ndcg result: 0.00229|0.00244|0.00247|0.00252\n",
      "2025-08-25 00:59:27,191 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:27,192 - yamyam - INFO - recall: 0.01098|0.01506|0.01506|0.01506|0.01506\n",
      "2025-08-25 00:59:27,192 - yamyam - INFO - [ all users metric report calculated from test data ]\n",
      "2025-08-25 00:59:27,194 - yamyam - INFO - top k results for direct prediction @3, @7, @10, @20 in order\n",
      "2025-08-25 00:59:27,194 - yamyam - INFO - map result: 0.00167|0.00173|0.00175|0.00178\n",
      "2025-08-25 00:59:27,195 - yamyam - INFO - ndcg result: 0.00171|0.00183|0.00188|0.00198\n",
      "2025-08-25 00:59:27,195 - yamyam - INFO - top k results for candidate generation @100, @300, @500, @1000, @2000\n",
      "2025-08-25 00:59:27,196 - yamyam - INFO - recall: 0.0096|0.01348|0.01348|0.01348|0.01348\n"
     ]
    }
   ],
   "source": [
    "# ===================== Variants: BALANCED vs BASED vs DIV_HEAVY =====================\n",
    "\n",
    "# (안전) logger 없으면 간단 세팅\n",
    "try:\n",
    "    logger\n",
    "except NameError:\n",
    "    import logging, sys\n",
    "    logger = logging.getLogger(\"rerank_test\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    h = logging.StreamHandler(sys.stdout)\n",
    "    h.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n",
    "    logger.addHandler(h)\n",
    "\n",
    "# 0) 공통 준비 --------------------------------------------------------------------------\n",
    "item_meta = data[\"diner_meta\"]\n",
    "\n",
    "# 후보/베이스 점수 \n",
    "candidates = np.array(data[\"most_popular_diner_ids\"], dtype=np.int64)\n",
    "base_scores = 1.0 / (np.arange(len(candidates)) + 1)\n",
    "\n",
    "meta_ids = item_meta[\"diner_idx\"]\n",
    "if not pd.api.types.is_integer_dtype(meta_ids.dtype):\n",
    "    meta_vals = pd.to_numeric(meta_ids, errors=\"coerce\").dropna().astype(np.int64).to_numpy()\n",
    "else:\n",
    "    meta_vals = meta_ids.to_numpy(dtype=np.int64, copy=False)\n",
    "\n",
    "mask = np.isin(candidates, meta_vals)\n",
    "dropped = int((~mask).sum())\n",
    "if dropped:\n",
    "    logger.warning(f\"dropped {dropped} candidates not in item_meta\")\n",
    "candidates = candidates[mask]\n",
    "base_scores = base_scores[mask]\n",
    "\n",
    "# K 고정\n",
    "k = int(max(top_k_values))\n",
    "\n",
    "# 결과 비교 로그\n",
    "def _log_variant(name: str, ref_ids: np.ndarray, var_ids: np.ndarray, k_show: int = 10):\n",
    "    ref_top = ref_ids[:k]\n",
    "    var_top = var_ids[:k]\n",
    "    overlap = len(set(ref_top) & set(var_top))\n",
    "    logger.info(f\"[{name}] overlap@K={overlap}/{k}\")\n",
    "    for i, (a, b) in enumerate(zip(ref_top, var_top)):\n",
    "        if a != b:\n",
    "            logger.info(f\"[{name}] first diff at pos {i}: ref={a}, var={b}\")\n",
    "            break\n",
    "    else:\n",
    "        logger.info(f\"[{name}] no diff within top-{k}\")\n",
    "    logger.info(f\"[{name}] head{ k_show } ref={ref_top[:k_show].tolist()}\")\n",
    "    logger.info(f\"[{name}] head{ k_show } var={var_top[:k_show].tolist()}\")\n",
    "\n",
    "# 메트릭 계산/리포트\n",
    "def _report_metrics(label: str, ids_seq):\n",
    "    seq = ids_seq.tolist() if isinstance(ids_seq, np.ndarray) else list(ids_seq)\n",
    "\n",
    "    # Validation\n",
    "    metric_dict = metric_calculator.generate_recommendations_and_calculate_metric(\n",
    "        X_train=data[\"X_train_df\"],\n",
    "        X_val_warm_users=data[\"X_val_warm_users\"],\n",
    "        X_val_cold_users=data[\"X_val_cold_users\"],\n",
    "        most_popular_diner_ids=seq,\n",
    "        filter_already_liked=True,\n",
    "        most_popular_rec_to_warm_users=True,\n",
    "    )\n",
    "    for user_type, metric in metric_dict.items():\n",
    "        metric_calculator.calculate_mean_metric(metric)\n",
    "    logger.info(f\"######## Validation metrics ({label}) ########\")\n",
    "    metric_calculator.report_metric_with_warm_cold_all_users(metric_dict=metric_dict, data_type=\"val\")\n",
    "\n",
    "    # Test\n",
    "    metric_dict = metric_calculator.generate_recommendations_and_calculate_metric(\n",
    "        X_train=data[\"X_train_df\"],\n",
    "        X_val_warm_users=data[\"X_test_warm_users\"],\n",
    "        X_val_cold_users=data[\"X_test_cold_users\"],\n",
    "        most_popular_diner_ids=seq,\n",
    "        filter_already_liked=True,\n",
    "        most_popular_rec_to_warm_users=True,\n",
    "    )\n",
    "    for user_type, metric in metric_dict.items():\n",
    "        metric_calculator.calculate_mean_metric(metric)\n",
    "    logger.info(f\"######## Test metrics ({label}) ########\")\n",
    "    metric_calculator.report_metric_with_warm_cold_all_users(metric_dict=metric_dict, data_type=\"test\")\n",
    "\n",
    "# 1) BALANCED -----------------------------------------------------\n",
    "balanced_ids, _ = rerank_region_periphery(\n",
    "    item_ids=candidates,\n",
    "    base_scores=base_scores,\n",
    "    item_meta_std=item_meta,\n",
    "    k=k,\n",
    "    region_label=\"서울 강남구\",\n",
    "    hotspot_coords=None,\n",
    "    n_auto_hotspots=5,       \n",
    "    periphery_strength=0.5,  \n",
    "    periphery_cap=0.15,\n",
    "    lambda_div=0.55,         \n",
    "    w_cat=0.5, w_geo=0.5,   \n",
    "    geo_tau_km=2.0,\n",
    ")\n",
    "logger.info(\"[BALANCED] generated\")\n",
    "\n",
    "# 2) BASED  -------------------------------------------------------------\n",
    "BASED_ids = candidates[:k].copy()\n",
    "logger.info(\"[BASED] generated\")\n",
    "\n",
    "# 3) DIV_HEAVY (다양성 극대화) ----------------------------------------------------------\n",
    "div_heavy_ids, _ = rerank_region_periphery(\n",
    "    item_ids=candidates,\n",
    "    base_scores=base_scores,\n",
    "    item_meta_std=item_meta,\n",
    "    k=k,\n",
    "    region_label=\"서울 강남구\",\n",
    "    hotspot_coords=None,\n",
    "    n_auto_hotspots=5,\n",
    "    periphery_strength=0.8,   \n",
    "    periphery_cap=0.30,\n",
    "    lambda_div=0.20,         \n",
    "    w_cat=0.0, w_geo=1.0,     \n",
    "    geo_tau_km=1.5,           \n",
    ")\n",
    "logger.info(\"[DIV_HEAVY] generated\")\n",
    "\n",
    "# 정확도 극대화\n",
    "# accuracy_heavy_ids, _ = rerank_region_periphery(\n",
    "#     item_ids=candidates, base_scores=base_scores, item_meta_std=item_meta, k=k,\n",
    "#     region_label=\"서울 강남구\", hotspot_coords=None, n_auto_hotspots=0,\n",
    "#     periphery_strength=0.0, periphery_cap=0.0,\n",
    "#     lambda_div=0.95, w_cat=1.0, w_geo=0.0, geo_tau_km=2.0\n",
    "# )\n",
    "\n",
    "_log_variant(\"BASED vs BALANCED\", balanced_ids, BASED_ids, k_show=10)\n",
    "_log_variant(\"DIV_HEAVY vs BALANCED\", balanced_ids, div_heavy_ids, k_show=10)\n",
    "# _log_variant(\"ACCURACY_HEAVY vs BALANCED\", balanced_ids, accuracy_heavy_ids, k_show=10)\n",
    "\n",
    "metric_calculator = MostPopularMetricCalculator(\n",
    "    top_k_values=top_k_values,\n",
    "    filter_already_liked=True,\n",
    "    recommend_batch_size=config.training.evaluation.recommend_batch_size,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "_report_metrics(\"BALANCED\", balanced_ids)\n",
    "_report_metrics(\"BASED\", BASED_ids)\n",
    "_report_metrics(\"DIV_HEAVY\", div_heavy_ids)\n",
    "# _report_metrics(\"ACCURACY_HEAVY\", accuracy_heavy_ids)\n",
    "\n",
    "reranked_most_popular = balanced_ids.tolist()\n",
    "# ======================================================================================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-fg4b1aLu-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
